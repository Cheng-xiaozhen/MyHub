{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "436d7e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chengxiaozhen/anaconda3/envs/forensichub2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2\n",
      "Current Torch version: 2.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "# 将项目根目录（MyHub）的父目录添加到系统路径中\n",
    "# 这使得 'MyHub' 本身可以被当作一个包来导入\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import json\n",
    "import torch\n",
    "import time\n",
    "import argparse\n",
    "import datetime\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import timm.optim.optim_factory as optim_factory\n",
    "from torch.utils.tensorboard.writer import SummaryWriter\n",
    "\n",
    "from MyHub.core.registry import DATASETS, MODELS, POSTFUNCS, TRANSFORMS, EVALUATORS, build_from_registry\n",
    "from MyHub.training_scripts.utils import misc\n",
    "from MyHub.training_scripts.utils.yaml import load_yaml_config,split_config, add_attr\n",
    "from MyHub.training_scripts.trainer import train_one_epoch\n",
    "from MyHub.training_scripts.tester import test_one_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a481dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(gpus='0,1', flag='train', log_dir='./log/resnet_train', if_predict_label=True, if_predict_mask=False, batch_size=2, test_batch_size=128, epochs=20, accum_iter=1, record_epoch=20, no_model_eval=False, test_period=1, log_per_epoch_count=20, find_unused_parameters=True, use_amp=False, weight_decay=0.05, lr=0.0001, blr=0.001, min_lr=1e-05, warmup_epochs=1, device='cuda', seed=42, resume='', start_epoch=0, num_workers=8, pin_mem=True, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', output_dir='./log/resnet_train', if_not_amp=True)\n",
      "{'name': 'Resnet101', 'init_config': {'output_type': 'label', 'image_size': 256}}\n",
      "{'name': 'CrossDataset', 'dataset_name': 'CrossDataset', 'init_config': {'dataset_config': [{'name': 'LabelDataset', 'pic_nums': 12641, 'init_config': {'image_size': 256, 'path': '/home/chengxiaozhen/Test/ForensicHub/MyHub/data/train_data/CASIAv2.json'}}]}}\n",
      "[{'name': 'LabelDataset', 'dataset_name': 'Coverage', 'init_config': {'image_size': 256, 'path': '/home/chengxiaozhen/Test/ForensicHub/MyHub/data/test_data/coverage.json', 'is_resizing': True, 'is_padding': False}}]\n",
      "{'name': 'CrossTransform', 'init_config': {}}\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser(description='Training Script')\n",
    "parser.add_argument('--config', default='config/resnet_train.yaml', help='path to config file', type=str)\n",
    "\n",
    "args = parser.parse_args(['--config', '/home/chengxiaozhen/Test/ForensicHub/MyHub/config/resnet_train.yaml'])\n",
    "\n",
    "config = load_yaml_config(args.config)\n",
    "args, model_args, train_dataset_args, test_dataset_args, transform_args, evaluator_args = split_config(config)\n",
    "add_attr(args,output_dir=args.log_dir)\n",
    "add_attr(args,if_not_amp=not args.use_amp)\n",
    "\n",
    "print(args)\n",
    "print(model_args)\n",
    "print(train_dataset_args)\n",
    "print(test_dataset_args)\n",
    "print(transform_args)\n",
    "\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c40183b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lazy import] 从MyHub.common.transforms.CrossTransform 加载 CrossTransform\n",
      "[build_from_registry] 创建模型 'CrossTransform' 参数: {}\n",
      "\n",
      "Train transform:  Compose([\n",
      "  HorizontalFlip(always_apply=False, p=0.5),\n",
      "  VerticalFlip(always_apply=False, p=0.5),\n",
      "  RandomBrightnessContrast(always_apply=False, p=1, brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), brightness_by_max=True),\n",
      "  ImageCompression(always_apply=False, p=0.2, quality_lower=70, quality_upper=100, compression_type=0),\n",
      "  RandomRotate90(always_apply=False, p=0.5),\n",
      "  GaussianBlur(always_apply=False, p=0.2, blur_limit=(3, 7), sigma_limit=(0, 0)),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n",
      "\n",
      "Test transform:  Compose([\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n",
      "\n",
      "Post transform:  Compose([\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
      "  ToTensorV2(always_apply=True, p=1.0, transpose_mask=True),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})\n"
     ]
    }
   ],
   "source": [
    "transform = build_from_registry(TRANSFORMS, transform_args)\n",
    "train_transform = transform.get_train_transform()\n",
    "test_transform = transform.get_test_transform()\n",
    "post_transform = transform.get_post_transform()\n",
    "print(\"\\nTrain transform: \", train_transform)\n",
    "print(\"\\nTest transform: \", test_transform)\n",
    "print(\"\\nPost transform: \", post_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3c25ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post function check: resnet101_post_func\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# get post function (if have)\n",
    "post_function_name = f\"{model_args['name']}_post_func\".lower()\n",
    "if model_args.get('post_func_name') is not None:\n",
    "    post_function_name = f\"{model_args['post_func_name']}_post_func\".lower()\n",
    "print(f\"Post function check: {post_function_name}\")\n",
    "if POSTFUNCS.has(post_function_name):\n",
    "    post_function = POSTFUNCS.get(post_function_name)\n",
    "else:\n",
    "    post_function = None\n",
    "print(post_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfefee40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lazy import] 从MyHub.common.datasets.CrossDataset 加载 CrossDataset\n",
      "[build_from_registry] 创建模型 'CrossDataset' 参数: {'dataset_config': [{'name': 'LabelDataset', 'pic_nums': 12641, 'init_config': {'image_size': 256, 'path': '/home/chengxiaozhen/Test/ForensicHub/MyHub/data/train_data/CASIAv2.json'}}], 'post_funcs': None, 'common_transform': Compose([\n",
      "  HorizontalFlip(always_apply=False, p=0.5),\n",
      "  VerticalFlip(always_apply=False, p=0.5),\n",
      "  RandomBrightnessContrast(always_apply=False, p=1, brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), brightness_by_max=True),\n",
      "  ImageCompression(always_apply=False, p=0.2, quality_lower=70, quality_upper=100, compression_type=0),\n",
      "  RandomRotate90(always_apply=False, p=0.5),\n",
      "  GaussianBlur(always_apply=False, p=0.2, blur_limit=(3, 7), sigma_limit=(0, 0)),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={}), 'post_transform': Compose([\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
      "  ToTensorV2(always_apply=True, p=1.0, transpose_mask=True),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})}\n",
      "[build_from_registry] 创建模型 'LabelDataset' 参数: {'image_size': 256, 'path': '/home/chengxiaozhen/Test/ForensicHub/MyHub/data/train_data/CASIAv2.json', 'common_transform': Compose([\n",
      "  HorizontalFlip(always_apply=False, p=0.5),\n",
      "  VerticalFlip(always_apply=False, p=0.5),\n",
      "  RandomBrightnessContrast(always_apply=False, p=1, brightness_limit=(-0.1, 0.1), contrast_limit=(-0.1, 0.1), brightness_by_max=True),\n",
      "  ImageCompression(always_apply=False, p=0.2, quality_lower=70, quality_upper=100, compression_type=0),\n",
      "  RandomRotate90(always_apply=False, p=0.5),\n",
      "  GaussianBlur(always_apply=False, p=0.2, blur_limit=(3, 7), sigma_limit=(0, 0)),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={}), 'post_transform': Compose([\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
      "  ToTensorV2(always_apply=True, p=1.0, transpose_mask=True),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={}), 'post_funcs': None}\n",
      "{'image', 'label'}\n"
     ]
    }
   ],
   "source": [
    "train_dataset_args[\"init_config\"].update({\n",
    "        \"post_funcs\": post_function,\n",
    "        \"common_transform\": train_transform,\n",
    "        \"post_transform\": post_transform\n",
    "    })\n",
    "train_dataset = build_from_registry(DATASETS, train_dataset_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6c69c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[build_from_registry] 创建模型 'LabelDataset' 参数: {'image_size': 256, 'path': '/home/chengxiaozhen/Test/ForensicHub/MyHub/data/test_data/coverage.json', 'is_resizing': True, 'is_padding': False, 'post_funcs': None, 'common_transform': Compose([\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={}), 'post_transform': Compose([\n",
      "  Normalize(always_apply=False, p=1.0, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0),\n",
      "  ToTensorV2(always_apply=True, p=1.0, transpose_mask=True),\n",
      "], p=1.0, bbox_params=None, keypoint_params=None, additional_targets={})}\n"
     ]
    }
   ],
   "source": [
    "test_dataset_list = {}\n",
    "for test_args in test_dataset_args:\n",
    "    test_args[\"init_config\"].update({\n",
    "        \"post_funcs\": post_function,\n",
    "        \"common_transform\": test_transform,\n",
    "        \"post_transform\": post_transform\n",
    "    })\n",
    "    test_dataset_list[test_args[\"dataset_name\"]] = build_from_registry(DATASETS, test_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3069295f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset: CrossDataset.\n",
      "12641\n",
      "<=== CrossDataset with 1 datasets: ['LabelDataset'] ===>\n",
      "\n",
      "[Dataset 0 - LabelDataset]\n",
      "LabelDataset from /home/chengxiaozhen/Test/ForensicHub/MyHub/data/train_data/CASIAv2.json\n",
      "Total samples: 12614\n",
      "Label 0 samples (real): 7491\n",
      "Label 1 samples (fake): 5123\n",
      "\n",
      "Total samples per epoch: 12,641\n",
      "<================================================>\n",
      "\n",
      "Test dataset: ['Coverage'].\n",
      "[200]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train dataset: {train_dataset_args['dataset_name']}.\")\n",
    "print(len(train_dataset))\n",
    "print(str(train_dataset))\n",
    "print(f\"Test dataset: {[args['dataset_name'] for args in test_dataset_args]}.\")\n",
    "print([len(dataset) for dataset in test_dataset_list.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6db0748",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sampler = {}\n",
    "sampler_train = torch.utils.data.RandomSampler(train_dataset)\n",
    "for test_dataset_name, dataset_test in test_dataset_list.items():\n",
    "    sampler_test = torch.utils.data.RandomSampler(dataset_test)\n",
    "    test_sampler[test_dataset_name] = sampler_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9917365b",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_rank = 0\n",
    "if global_rank == 0 and args.log_dir is not None:\n",
    "    os.makedirs(args.log_dir, exist_ok=True)\n",
    "    log_writer = SummaryWriter(log_dir=args.log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90b3ab5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader_train = torch.utils.data.DataLoader(\n",
    "    train_dataset, \n",
    "    sampler=sampler_train,\n",
    "    batch_size=args.batch_size,\n",
    "    num_workers=args.num_workers,\n",
    "    pin_memory=args.pin_mem,\n",
    "    drop_last=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed882b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloaders = {}\n",
    "for test_dataset_name in test_sampler.keys():\n",
    "    test_dataloader = torch.utils.data.DataLoader(\n",
    "        test_dataset_list[test_dataset_name],\n",
    "        sampler=test_sampler[test_dataset_name],\n",
    "        batch_size=args.test_batch_size,\n",
    "        num_workers=args.num_workers,\n",
    "        pin_memory=args.pin_mem,\n",
    "        drop_last=True,\n",
    "    )\n",
    "    test_dataloaders[test_dataset_name] = test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "facc6dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lazy import] 从MyHub.common.backbones.resnet 加载 Resnet101\n",
      "[build_from_registry] 创建模型 'Resnet101' 参数: {'output_type': 'label', 'image_size': 256}\n"
     ]
    }
   ],
   "source": [
    "model = build_from_registry(MODELS, model_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e9750d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Lazy import] 从MyHub.common.evaluations.F1 加载 ImageF1\n",
      "[build_from_registry] 创建模型 'ImageF1' 参数: {'threshold': 0.5}\n",
      "Evaluators: [<MyHub.common.evaluations.F1.ImageF1 object at 0x7fca58f91cc0>]\n"
     ]
    }
   ],
   "source": [
    "evaluator_list = []\n",
    "for eva_args in evaluator_args:\n",
    "    evaluator_list.append(build_from_registry(EVALUATORS, eva_args))\n",
    "print(f\"Evaluators: {evaluator_list}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "294107bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(args.device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b38b6793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base lr: 1.28e-02\n",
      "actual lr: 1.00e-04\n",
      "accumulate grad iterations: 1\n",
      "effective batch size: 2\n"
     ]
    }
   ],
   "source": [
    "eff_batch_size = args.batch_size * args.accum_iter * misc.get_world_size()\n",
    "if args.lr is None:  # only base_lr is specified\n",
    "    args.lr = args.blr * eff_batch_size / 256\n",
    "\n",
    "print(\"base lr: %.2e\" % (args.lr * 256 / eff_batch_size))\n",
    "print(\"actual lr: %.2e\" % args.lr)\n",
    "print(\"accumulate grad iterations: %d\" % args.accum_iter)\n",
    "print(\"effective batch size: %d\" % eff_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2aa7f71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdamW (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.0\n",
      "\n",
      "Parameter Group 1\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    lr: 0.0001\n",
      "    maximize: False\n",
      "    weight_decay: 0.05\n",
      ")\n",
      "Start training for 20 epochs\n"
     ]
    }
   ],
   "source": [
    "args.opt = 'AdamW'\n",
    "args.betas = (0.9, 0.999)\n",
    "args.momentum = 0.9\n",
    "optimizer = optim_factory.create_optimizer(args, model)\n",
    "print(optimizer)\n",
    "loss_scaler = misc.NativeScalerWithGradNormCount()\n",
    "\n",
    "misc.load_model(args=args, model_without_ddp=model, optimizer=optimizer, loss_scaler=loss_scaler)\n",
    "\n",
    "print(f\"Start training for {args.epochs} epochs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "faa9d55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Auto Mixed Precision (AMP) is disabled.\n",
      "log_dir: ./log/resnet_train\n",
      "Epoch: [0]  [   0/6320]  eta: 1:38:18  lr: 0.000000  combined_loss: [local: 0.6877 | reduced: 0.6877]  time: 0.9333  data: 0.2728  max mem: 841\n",
      "Epoch: [0]  [  20/6320]  eta: 0:10:52  lr: 0.000000  combined_loss: [local: 0.6749 | reduced: 0.6781]  time: 0.0621  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [  40/6320]  eta: 0:08:44  lr: 0.000001  combined_loss: [local: 0.6899 | reduced: 0.6824]  time: 0.0623  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [  60/6320]  eta: 0:07:59  lr: 0.000001  combined_loss: [local: 0.6884 | reduced: 0.6827]  time: 0.0626  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [  80/6320]  eta: 0:07:36  lr: 0.000001  combined_loss: [local: 0.6859 | reduced: 0.6834]  time: 0.0627  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 100/6320]  eta: 0:07:22  lr: 0.000002  combined_loss: [local: 0.6809 | reduced: 0.6838]  time: 0.0628  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 120/6320]  eta: 0:07:12  lr: 0.000002  combined_loss: [local: 0.6877 | reduced: 0.6845]  time: 0.0628  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 140/6320]  eta: 0:07:04  lr: 0.000002  combined_loss: [local: 0.6836 | reduced: 0.6875]  time: 0.0626  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 160/6320]  eta: 0:06:59  lr: 0.000003  combined_loss: [local: 0.6893 | reduced: 0.6881]  time: 0.0629  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 180/6320]  eta: 0:06:53  lr: 0.000003  combined_loss: [local: 0.6807 | reduced: 0.6871]  time: 0.0620  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 200/6320]  eta: 0:06:49  lr: 0.000003  combined_loss: [local: 0.6924 | reduced: 0.6872]  time: 0.0627  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 220/6320]  eta: 0:06:45  lr: 0.000003  combined_loss: [local: 0.6796 | reduced: 0.6863]  time: 0.0621  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 240/6320]  eta: 0:06:42  lr: 0.000004  combined_loss: [local: 0.6901 | reduced: 0.6871]  time: 0.0624  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 260/6320]  eta: 0:06:38  lr: 0.000004  combined_loss: [local: 0.6880 | reduced: 0.6870]  time: 0.0625  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 280/6320]  eta: 0:06:36  lr: 0.000004  combined_loss: [local: 0.6888 | reduced: 0.6871]  time: 0.0627  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 300/6320]  eta: 0:06:33  lr: 0.000005  combined_loss: [local: 0.6875 | reduced: 0.6875]  time: 0.0625  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 320/6320]  eta: 0:06:31  lr: 0.000005  combined_loss: [local: 0.6706 | reduced: 0.6869]  time: 0.0629  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 340/6320]  eta: 0:06:29  lr: 0.000005  combined_loss: [local: 0.6647 | reduced: 0.6856]  time: 0.0627  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 360/6320]  eta: 0:06:27  lr: 0.000006  combined_loss: [local: 0.6960 | reduced: 0.6861]  time: 0.0628  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 380/6320]  eta: 0:06:25  lr: 0.000006  combined_loss: [local: 0.6908 | reduced: 0.6865]  time: 0.0628  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 400/6320]  eta: 0:06:23  lr: 0.000006  combined_loss: [local: 0.6952 | reduced: 0.6868]  time: 0.0627  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 420/6320]  eta: 0:06:21  lr: 0.000007  combined_loss: [local: 0.6824 | reduced: 0.6865]  time: 0.0626  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 440/6320]  eta: 0:06:19  lr: 0.000007  combined_loss: [local: 0.6991 | reduced: 0.6875]  time: 0.0624  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 460/6320]  eta: 0:06:17  lr: 0.000007  combined_loss: [local: 0.6679 | reduced: 0.6870]  time: 0.0629  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 480/6320]  eta: 0:06:16  lr: 0.000008  combined_loss: [local: 0.6932 | reduced: 0.6870]  time: 0.0625  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 500/6320]  eta: 0:06:14  lr: 0.000008  combined_loss: [local: 0.6499 | reduced: 0.6867]  time: 0.0626  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 520/6320]  eta: 0:06:12  lr: 0.000008  combined_loss: [local: 0.6615 | reduced: 0.6860]  time: 0.0630  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 540/6320]  eta: 0:06:11  lr: 0.000009  combined_loss: [local: 0.6738 | reduced: 0.6863]  time: 0.0628  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 560/6320]  eta: 0:06:09  lr: 0.000009  combined_loss: [local: 0.6796 | reduced: 0.6860]  time: 0.0645  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 580/6320]  eta: 0:06:08  lr: 0.000009  combined_loss: [local: 0.6896 | reduced: 0.6859]  time: 0.0623  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 600/6320]  eta: 0:06:06  lr: 0.000009  combined_loss: [local: 0.6600 | reduced: 0.6849]  time: 0.0630  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 620/6320]  eta: 0:06:05  lr: 0.000010  combined_loss: [local: 0.6815 | reduced: 0.6851]  time: 0.0622  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 640/6320]  eta: 0:06:03  lr: 0.000010  combined_loss: [local: 0.6641 | reduced: 0.6837]  time: 0.0627  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 660/6320]  eta: 0:06:02  lr: 0.000010  combined_loss: [local: 0.6503 | reduced: 0.6825]  time: 0.0624  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 680/6320]  eta: 0:06:00  lr: 0.000011  combined_loss: [local: 0.6908 | reduced: 0.6822]  time: 0.0627  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 700/6320]  eta: 0:05:59  lr: 0.000011  combined_loss: [local: 0.7101 | reduced: 0.6831]  time: 0.0625  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 720/6320]  eta: 0:05:57  lr: 0.000011  combined_loss: [local: 0.6839 | reduced: 0.6830]  time: 0.0627  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 740/6320]  eta: 0:05:56  lr: 0.000012  combined_loss: [local: 0.6230 | reduced: 0.6818]  time: 0.0624  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 760/6320]  eta: 0:05:54  lr: 0.000012  combined_loss: [local: 0.6759 | reduced: 0.6811]  time: 0.0627  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 780/6320]  eta: 0:05:53  lr: 0.000012  combined_loss: [local: 0.6984 | reduced: 0.6812]  time: 0.0628  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 800/6320]  eta: 0:05:51  lr: 0.000013  combined_loss: [local: 0.6805 | reduced: 0.6802]  time: 0.0626  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 820/6320]  eta: 0:05:50  lr: 0.000013  combined_loss: [local: 0.6796 | reduced: 0.6792]  time: 0.0631  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 840/6320]  eta: 0:05:49  lr: 0.000013  combined_loss: [local: 0.6013 | reduced: 0.6781]  time: 0.0683  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [ 860/6320]  eta: 0:05:49  lr: 0.000014  combined_loss: [local: 0.5976 | reduced: 0.6774]  time: 0.0744  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [ 880/6320]  eta: 0:05:50  lr: 0.000014  combined_loss: [local: 0.7352 | reduced: 0.6792]  time: 0.0761  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [ 900/6320]  eta: 0:05:50  lr: 0.000014  combined_loss: [local: 0.6956 | reduced: 0.6802]  time: 0.0759  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [ 920/6320]  eta: 0:05:50  lr: 0.000015  combined_loss: [local: 0.6815 | reduced: 0.6808]  time: 0.0762  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [ 940/6320]  eta: 0:05:50  lr: 0.000015  combined_loss: [local: 0.6955 | reduced: 0.6812]  time: 0.0754  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [ 960/6320]  eta: 0:05:49  lr: 0.000015  combined_loss: [local: 0.7044 | reduced: 0.6820]  time: 0.0755  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [ 980/6320]  eta: 0:05:49  lr: 0.000016  combined_loss: [local: 0.6886 | reduced: 0.6822]  time: 0.0751  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1000/6320]  eta: 0:05:49  lr: 0.000016  combined_loss: [local: 0.6497 | reduced: 0.6818]  time: 0.0759  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [1020/6320]  eta: 0:05:49  lr: 0.000016  combined_loss: [local: 0.6776 | reduced: 0.6816]  time: 0.0758  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1040/6320]  eta: 0:05:48  lr: 0.000016  combined_loss: [local: 0.6804 | reduced: 0.6820]  time: 0.0761  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1060/6320]  eta: 0:05:48  lr: 0.000017  combined_loss: [local: 0.7231 | reduced: 0.6821]  time: 0.0753  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [1080/6320]  eta: 0:05:48  lr: 0.000017  combined_loss: [local: 0.6634 | reduced: 0.6822]  time: 0.0759  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [1100/6320]  eta: 0:05:47  lr: 0.000017  combined_loss: [local: 0.6759 | reduced: 0.6820]  time: 0.0755  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [1120/6320]  eta: 0:05:47  lr: 0.000018  combined_loss: [local: 0.6281 | reduced: 0.6816]  time: 0.0761  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1140/6320]  eta: 0:05:46  lr: 0.000018  combined_loss: [local: 0.6937 | reduced: 0.6818]  time: 0.0761  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [1160/6320]  eta: 0:05:46  lr: 0.000018  combined_loss: [local: 0.6896 | reduced: 0.6819]  time: 0.0762  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1180/6320]  eta: 0:05:45  lr: 0.000019  combined_loss: [local: 0.6987 | reduced: 0.6825]  time: 0.0758  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1200/6320]  eta: 0:05:45  lr: 0.000019  combined_loss: [local: 0.6491 | reduced: 0.6822]  time: 0.0760  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1220/6320]  eta: 0:05:44  lr: 0.000019  combined_loss: [local: 0.6951 | reduced: 0.6824]  time: 0.0760  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1240/6320]  eta: 0:05:43  lr: 0.000020  combined_loss: [local: 0.6857 | reduced: 0.6823]  time: 0.0762  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1260/6320]  eta: 0:05:43  lr: 0.000020  combined_loss: [local: 0.6879 | reduced: 0.6819]  time: 0.0760  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1280/6320]  eta: 0:05:42  lr: 0.000020  combined_loss: [local: 0.7023 | reduced: 0.6828]  time: 0.0754  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1300/6320]  eta: 0:05:41  lr: 0.000021  combined_loss: [local: 0.6907 | reduced: 0.6826]  time: 0.0756  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1320/6320]  eta: 0:05:41  lr: 0.000021  combined_loss: [local: 0.6819 | reduced: 0.6823]  time: 0.0786  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1340/6320]  eta: 0:05:40  lr: 0.000021  combined_loss: [local: 0.6763 | reduced: 0.6822]  time: 0.0804  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1360/6320]  eta: 0:05:39  lr: 0.000022  combined_loss: [local: 0.6099 | reduced: 0.6814]  time: 0.0788  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1380/6320]  eta: 0:05:39  lr: 0.000022  combined_loss: [local: 0.6994 | reduced: 0.6815]  time: 0.0782  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1400/6320]  eta: 0:05:38  lr: 0.000022  combined_loss: [local: 0.6563 | reduced: 0.6811]  time: 0.0785  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [1420/6320]  eta: 0:05:37  lr: 0.000022  combined_loss: [local: 0.4920 | reduced: 0.6794]  time: 0.0782  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [1440/6320]  eta: 0:05:36  lr: 0.000023  combined_loss: [local: 0.6878 | reduced: 0.6788]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1460/6320]  eta: 0:05:36  lr: 0.000023  combined_loss: [local: 0.7182 | reduced: 0.6794]  time: 0.0760  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1480/6320]  eta: 0:05:35  lr: 0.000023  combined_loss: [local: 0.7000 | reduced: 0.6806]  time: 0.0760  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [1500/6320]  eta: 0:05:34  lr: 0.000024  combined_loss: [local: 0.6090 | reduced: 0.6799]  time: 0.0753  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1520/6320]  eta: 0:05:33  lr: 0.000024  combined_loss: [local: 0.7111 | reduced: 0.6801]  time: 0.0758  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1540/6320]  eta: 0:05:32  lr: 0.000024  combined_loss: [local: 0.6545 | reduced: 0.6797]  time: 0.0759  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [1560/6320]  eta: 0:05:31  lr: 0.000025  combined_loss: [local: 0.6802 | reduced: 0.6802]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1580/6320]  eta: 0:05:30  lr: 0.000025  combined_loss: [local: 0.6516 | reduced: 0.6798]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1600/6320]  eta: 0:05:29  lr: 0.000025  combined_loss: [local: 0.6752 | reduced: 0.6798]  time: 0.0755  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1620/6320]  eta: 0:05:28  lr: 0.000026  combined_loss: [local: 0.6107 | reduced: 0.6792]  time: 0.0756  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1640/6320]  eta: 0:05:26  lr: 0.000026  combined_loss: [local: 0.6955 | reduced: 0.6792]  time: 0.0759  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1660/6320]  eta: 0:05:25  lr: 0.000026  combined_loss: [local: 0.7001 | reduced: 0.6790]  time: 0.0759  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1680/6320]  eta: 0:05:24  lr: 0.000027  combined_loss: [local: 0.5433 | reduced: 0.6783]  time: 0.0755  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1700/6320]  eta: 0:05:23  lr: 0.000027  combined_loss: [local: 0.6868 | reduced: 0.6785]  time: 0.0757  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [1720/6320]  eta: 0:05:22  lr: 0.000027  combined_loss: [local: 0.6843 | reduced: 0.6781]  time: 0.0754  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1740/6320]  eta: 0:05:21  lr: 0.000028  combined_loss: [local: 0.6401 | reduced: 0.6781]  time: 0.0759  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1760/6320]  eta: 0:05:20  lr: 0.000028  combined_loss: [local: 0.6967 | reduced: 0.6782]  time: 0.0759  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1780/6320]  eta: 0:05:19  lr: 0.000028  combined_loss: [local: 0.6831 | reduced: 0.6782]  time: 0.0754  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [1800/6320]  eta: 0:05:18  lr: 0.000028  combined_loss: [local: 0.5783 | reduced: 0.6778]  time: 0.0759  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1820/6320]  eta: 0:05:17  lr: 0.000029  combined_loss: [local: 0.7124 | reduced: 0.6782]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1840/6320]  eta: 0:05:15  lr: 0.000029  combined_loss: [local: 0.6558 | reduced: 0.6781]  time: 0.0755  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1860/6320]  eta: 0:05:14  lr: 0.000029  combined_loss: [local: 0.6471 | reduced: 0.6780]  time: 0.0749  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1880/6320]  eta: 0:05:13  lr: 0.000030  combined_loss: [local: 0.5641 | reduced: 0.6777]  time: 0.0753  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1900/6320]  eta: 0:05:12  lr: 0.000030  combined_loss: [local: 0.7059 | reduced: 0.6779]  time: 0.0754  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1920/6320]  eta: 0:05:11  lr: 0.000030  combined_loss: [local: 0.6416 | reduced: 0.6777]  time: 0.0760  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1940/6320]  eta: 0:05:09  lr: 0.000031  combined_loss: [local: 0.6972 | reduced: 0.6779]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1960/6320]  eta: 0:05:08  lr: 0.000031  combined_loss: [local: 0.6387 | reduced: 0.6777]  time: 0.0755  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [1980/6320]  eta: 0:05:07  lr: 0.000031  combined_loss: [local: 0.6337 | reduced: 0.6774]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2000/6320]  eta: 0:05:06  lr: 0.000032  combined_loss: [local: 0.6829 | reduced: 0.6774]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2020/6320]  eta: 0:05:05  lr: 0.000032  combined_loss: [local: 0.6217 | reduced: 0.6769]  time: 0.0754  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2040/6320]  eta: 0:05:03  lr: 0.000032  combined_loss: [local: 0.7064 | reduced: 0.6772]  time: 0.0753  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2060/6320]  eta: 0:05:02  lr: 0.000033  combined_loss: [local: 0.6707 | reduced: 0.6772]  time: 0.0756  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2080/6320]  eta: 0:05:01  lr: 0.000033  combined_loss: [local: 0.6556 | reduced: 0.6771]  time: 0.0814  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [2100/6320]  eta: 0:05:00  lr: 0.000033  combined_loss: [local: 0.6945 | reduced: 0.6772]  time: 0.0724  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2120/6320]  eta: 0:04:58  lr: 0.000034  combined_loss: [local: 0.5493 | reduced: 0.6768]  time: 0.0712  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2140/6320]  eta: 0:04:57  lr: 0.000034  combined_loss: [local: 0.6541 | reduced: 0.6765]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2160/6320]  eta: 0:04:56  lr: 0.000034  combined_loss: [local: 0.5934 | reduced: 0.6764]  time: 0.0762  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2180/6320]  eta: 0:04:55  lr: 0.000034  combined_loss: [local: 0.6410 | reduced: 0.6765]  time: 0.0761  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2200/6320]  eta: 0:04:53  lr: 0.000035  combined_loss: [local: 0.6683 | reduced: 0.6763]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2220/6320]  eta: 0:04:52  lr: 0.000035  combined_loss: [local: 0.6635 | reduced: 0.6765]  time: 0.0761  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2240/6320]  eta: 0:04:51  lr: 0.000035  combined_loss: [local: 0.6522 | reduced: 0.6765]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2260/6320]  eta: 0:04:50  lr: 0.000036  combined_loss: [local: 0.5884 | reduced: 0.6762]  time: 0.0765  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2280/6320]  eta: 0:04:48  lr: 0.000036  combined_loss: [local: 0.6769 | reduced: 0.6763]  time: 0.0765  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [2300/6320]  eta: 0:04:47  lr: 0.000036  combined_loss: [local: 0.7048 | reduced: 0.6766]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2320/6320]  eta: 0:04:46  lr: 0.000037  combined_loss: [local: 0.6691 | reduced: 0.6764]  time: 0.0761  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2340/6320]  eta: 0:04:45  lr: 0.000037  combined_loss: [local: 0.6799 | reduced: 0.6763]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2360/6320]  eta: 0:04:43  lr: 0.000037  combined_loss: [local: 0.6406 | reduced: 0.6761]  time: 0.0760  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2380/6320]  eta: 0:04:42  lr: 0.000038  combined_loss: [local: 0.6094 | reduced: 0.6758]  time: 0.0760  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2400/6320]  eta: 0:04:41  lr: 0.000038  combined_loss: [local: 0.6945 | reduced: 0.6759]  time: 0.0762  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2420/6320]  eta: 0:04:39  lr: 0.000038  combined_loss: [local: 0.6867 | reduced: 0.6761]  time: 0.0760  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2440/6320]  eta: 0:04:38  lr: 0.000039  combined_loss: [local: 0.6426 | reduced: 0.6758]  time: 0.0760  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [2460/6320]  eta: 0:04:37  lr: 0.000039  combined_loss: [local: 0.6682 | reduced: 0.6757]  time: 0.0761  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2480/6320]  eta: 0:04:36  lr: 0.000039  combined_loss: [local: 0.6338 | reduced: 0.6754]  time: 0.0766  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2500/6320]  eta: 0:04:34  lr: 0.000040  combined_loss: [local: 0.7122 | reduced: 0.6758]  time: 0.0760  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2520/6320]  eta: 0:04:33  lr: 0.000040  combined_loss: [local: 0.6742 | reduced: 0.6760]  time: 0.0765  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2540/6320]  eta: 0:04:32  lr: 0.000040  combined_loss: [local: 0.6726 | reduced: 0.6760]  time: 0.0763  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2560/6320]  eta: 0:04:30  lr: 0.000041  combined_loss: [local: 0.6663 | reduced: 0.6761]  time: 0.0766  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2580/6320]  eta: 0:04:29  lr: 0.000041  combined_loss: [local: 0.6459 | reduced: 0.6759]  time: 0.0764  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [2600/6320]  eta: 0:04:28  lr: 0.000041  combined_loss: [local: 0.6566 | reduced: 0.6761]  time: 0.0762  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [2620/6320]  eta: 0:04:26  lr: 0.000041  combined_loss: [local: 0.6569 | reduced: 0.6761]  time: 0.0761  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2640/6320]  eta: 0:04:25  lr: 0.000042  combined_loss: [local: 0.6671 | reduced: 0.6762]  time: 0.0763  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2660/6320]  eta: 0:04:24  lr: 0.000042  combined_loss: [local: 0.6258 | reduced: 0.6760]  time: 0.0763  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [2680/6320]  eta: 0:04:22  lr: 0.000042  combined_loss: [local: 0.6818 | reduced: 0.6760]  time: 0.0766  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2700/6320]  eta: 0:04:21  lr: 0.000043  combined_loss: [local: 0.6524 | reduced: 0.6760]  time: 0.0761  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2720/6320]  eta: 0:04:20  lr: 0.000043  combined_loss: [local: 0.6641 | reduced: 0.6759]  time: 0.0768  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2740/6320]  eta: 0:04:18  lr: 0.000043  combined_loss: [local: 0.5405 | reduced: 0.6755]  time: 0.0765  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2760/6320]  eta: 0:04:17  lr: 0.000044  combined_loss: [local: 0.6883 | reduced: 0.6757]  time: 0.0769  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2780/6320]  eta: 0:04:16  lr: 0.000044  combined_loss: [local: 0.6517 | reduced: 0.6755]  time: 0.0761  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2800/6320]  eta: 0:04:14  lr: 0.000044  combined_loss: [local: 0.6135 | reduced: 0.6751]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2820/6320]  eta: 0:04:13  lr: 0.000045  combined_loss: [local: 0.5138 | reduced: 0.6743]  time: 0.0778  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2840/6320]  eta: 0:04:12  lr: 0.000045  combined_loss: [local: 0.6762 | reduced: 0.6739]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2860/6320]  eta: 0:04:10  lr: 0.000045  combined_loss: [local: 0.7162 | reduced: 0.6740]  time: 0.0752  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [2880/6320]  eta: 0:04:09  lr: 0.000046  combined_loss: [local: 0.6287 | reduced: 0.6737]  time: 0.0756  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2900/6320]  eta: 0:04:08  lr: 0.000046  combined_loss: [local: 0.6713 | reduced: 0.6735]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2920/6320]  eta: 0:04:06  lr: 0.000046  combined_loss: [local: 0.5357 | reduced: 0.6729]  time: 0.0751  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2940/6320]  eta: 0:04:05  lr: 0.000047  combined_loss: [local: 0.7103 | reduced: 0.6733]  time: 0.0753  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2960/6320]  eta: 0:04:03  lr: 0.000047  combined_loss: [local: 0.6342 | reduced: 0.6735]  time: 0.0747  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [2980/6320]  eta: 0:04:02  lr: 0.000047  combined_loss: [local: 0.6957 | reduced: 0.6735]  time: 0.0746  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3000/6320]  eta: 0:04:01  lr: 0.000047  combined_loss: [local: 0.6665 | reduced: 0.6735]  time: 0.0754  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3020/6320]  eta: 0:03:59  lr: 0.000048  combined_loss: [local: 0.6750 | reduced: 0.6735]  time: 0.0754  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3040/6320]  eta: 0:03:58  lr: 0.000048  combined_loss: [local: 0.6996 | reduced: 0.6739]  time: 0.0756  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3060/6320]  eta: 0:03:56  lr: 0.000048  combined_loss: [local: 0.6706 | reduced: 0.6741]  time: 0.0755  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3080/6320]  eta: 0:03:55  lr: 0.000049  combined_loss: [local: 0.6584 | reduced: 0.6740]  time: 0.0754  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3100/6320]  eta: 0:03:54  lr: 0.000049  combined_loss: [local: 0.6162 | reduced: 0.6737]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3120/6320]  eta: 0:03:52  lr: 0.000049  combined_loss: [local: 0.5545 | reduced: 0.6732]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3140/6320]  eta: 0:03:51  lr: 0.000050  combined_loss: [local: 0.7070 | reduced: 0.6736]  time: 0.0755  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3160/6320]  eta: 0:03:49  lr: 0.000050  combined_loss: [local: 0.6878 | reduced: 0.6737]  time: 0.0756  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3180/6320]  eta: 0:03:48  lr: 0.000050  combined_loss: [local: 0.6091 | reduced: 0.6736]  time: 0.0784  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3200/6320]  eta: 0:03:47  lr: 0.000051  combined_loss: [local: 0.6408 | reduced: 0.6735]  time: 0.0752  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3220/6320]  eta: 0:03:45  lr: 0.000051  combined_loss: [local: 0.6615 | reduced: 0.6733]  time: 0.0758  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3240/6320]  eta: 0:03:44  lr: 0.000051  combined_loss: [local: 0.6130 | reduced: 0.6730]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3260/6320]  eta: 0:03:42  lr: 0.000052  combined_loss: [local: 0.6605 | reduced: 0.6733]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3280/6320]  eta: 0:03:41  lr: 0.000052  combined_loss: [local: 0.5664 | reduced: 0.6730]  time: 0.0762  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3300/6320]  eta: 0:03:40  lr: 0.000052  combined_loss: [local: 0.6316 | reduced: 0.6731]  time: 0.0756  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3320/6320]  eta: 0:03:38  lr: 0.000053  combined_loss: [local: 0.5959 | reduced: 0.6732]  time: 0.0763  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [3340/6320]  eta: 0:03:37  lr: 0.000053  combined_loss: [local: 0.6257 | reduced: 0.6733]  time: 0.0767  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3360/6320]  eta: 0:03:35  lr: 0.000053  combined_loss: [local: 0.6162 | reduced: 0.6732]  time: 0.0761  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3380/6320]  eta: 0:03:34  lr: 0.000053  combined_loss: [local: 0.5687 | reduced: 0.6728]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3400/6320]  eta: 0:03:33  lr: 0.000054  combined_loss: [local: 0.6154 | reduced: 0.6728]  time: 0.0723  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3420/6320]  eta: 0:03:31  lr: 0.000054  combined_loss: [local: 0.6155 | reduced: 0.6728]  time: 0.0733  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3440/6320]  eta: 0:03:30  lr: 0.000054  combined_loss: [local: 0.5881 | reduced: 0.6728]  time: 0.0725  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3460/6320]  eta: 0:03:28  lr: 0.000055  combined_loss: [local: 0.5896 | reduced: 0.6728]  time: 0.0708  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3480/6320]  eta: 0:03:27  lr: 0.000055  combined_loss: [local: 0.6534 | reduced: 0.6730]  time: 0.0775  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3500/6320]  eta: 0:03:25  lr: 0.000055  combined_loss: [local: 0.6347 | reduced: 0.6730]  time: 0.0785  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3520/6320]  eta: 0:03:24  lr: 0.000056  combined_loss: [local: 0.6443 | reduced: 0.6733]  time: 0.0785  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3540/6320]  eta: 0:03:23  lr: 0.000056  combined_loss: [local: 0.6340 | reduced: 0.6732]  time: 0.0782  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3560/6320]  eta: 0:03:21  lr: 0.000056  combined_loss: [local: 0.6355 | reduced: 0.6732]  time: 0.0750  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3580/6320]  eta: 0:03:20  lr: 0.000057  combined_loss: [local: 0.6360 | reduced: 0.6732]  time: 0.0759  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3600/6320]  eta: 0:03:18  lr: 0.000057  combined_loss: [local: 0.6655 | reduced: 0.6731]  time: 0.0768  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [3620/6320]  eta: 0:03:17  lr: 0.000057  combined_loss: [local: 0.5767 | reduced: 0.6729]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3640/6320]  eta: 0:03:16  lr: 0.000058  combined_loss: [local: 0.6712 | reduced: 0.6733]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3660/6320]  eta: 0:03:14  lr: 0.000058  combined_loss: [local: 0.5932 | reduced: 0.6732]  time: 0.0768  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [3680/6320]  eta: 0:03:13  lr: 0.000058  combined_loss: [local: 0.7141 | reduced: 0.6735]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3700/6320]  eta: 0:03:11  lr: 0.000059  combined_loss: [local: 0.6248 | reduced: 0.6733]  time: 0.0760  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3720/6320]  eta: 0:03:10  lr: 0.000059  combined_loss: [local: 0.7449 | reduced: 0.6737]  time: 0.0765  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3740/6320]  eta: 0:03:08  lr: 0.000059  combined_loss: [local: 0.6485 | reduced: 0.6736]  time: 0.0767  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3760/6320]  eta: 0:03:07  lr: 0.000059  combined_loss: [local: 0.6283 | reduced: 0.6736]  time: 0.0762  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [3780/6320]  eta: 0:03:06  lr: 0.000060  combined_loss: [local: 0.6111 | reduced: 0.6735]  time: 0.0732  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3800/6320]  eta: 0:03:04  lr: 0.000060  combined_loss: [local: 0.6698 | reduced: 0.6736]  time: 0.0758  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3820/6320]  eta: 0:03:03  lr: 0.000060  combined_loss: [local: 0.6411 | reduced: 0.6736]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3840/6320]  eta: 0:03:01  lr: 0.000061  combined_loss: [local: 0.6073 | reduced: 0.6736]  time: 0.0761  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [3860/6320]  eta: 0:03:00  lr: 0.000061  combined_loss: [local: 0.6581 | reduced: 0.6737]  time: 0.0781  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3880/6320]  eta: 0:02:58  lr: 0.000061  combined_loss: [local: 0.6467 | reduced: 0.6737]  time: 0.0775  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3900/6320]  eta: 0:02:57  lr: 0.000062  combined_loss: [local: 0.6677 | reduced: 0.6738]  time: 0.0789  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [3920/6320]  eta: 0:02:56  lr: 0.000062  combined_loss: [local: 0.6558 | reduced: 0.6738]  time: 0.0834  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3940/6320]  eta: 0:02:54  lr: 0.000062  combined_loss: [local: 0.6717 | reduced: 0.6738]  time: 0.0834  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [3960/6320]  eta: 0:02:53  lr: 0.000063  combined_loss: [local: 0.6249 | reduced: 0.6737]  time: 0.0835  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [3980/6320]  eta: 0:02:52  lr: 0.000063  combined_loss: [local: 0.5738 | reduced: 0.6736]  time: 0.0839  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4000/6320]  eta: 0:02:50  lr: 0.000063  combined_loss: [local: 0.6053 | reduced: 0.6735]  time: 0.0834  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4020/6320]  eta: 0:02:49  lr: 0.000064  combined_loss: [local: 0.6526 | reduced: 0.6736]  time: 0.0839  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4040/6320]  eta: 0:02:48  lr: 0.000064  combined_loss: [local: 0.6026 | reduced: 0.6734]  time: 0.0830  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4060/6320]  eta: 0:02:46  lr: 0.000064  combined_loss: [local: 0.5823 | reduced: 0.6732]  time: 0.0838  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4080/6320]  eta: 0:02:45  lr: 0.000065  combined_loss: [local: 0.4981 | reduced: 0.6729]  time: 0.0829  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4100/6320]  eta: 0:02:44  lr: 0.000065  combined_loss: [local: 0.5398 | reduced: 0.6727]  time: 0.0837  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4120/6320]  eta: 0:02:42  lr: 0.000065  combined_loss: [local: 0.6687 | reduced: 0.6729]  time: 0.0829  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4140/6320]  eta: 0:02:41  lr: 0.000066  combined_loss: [local: 0.6177 | reduced: 0.6729]  time: 0.0836  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [4160/6320]  eta: 0:02:39  lr: 0.000066  combined_loss: [local: 0.6142 | reduced: 0.6728]  time: 0.0828  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4180/6320]  eta: 0:02:38  lr: 0.000066  combined_loss: [local: 0.5811 | reduced: 0.6728]  time: 0.0793  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4200/6320]  eta: 0:02:37  lr: 0.000066  combined_loss: [local: 0.5951 | reduced: 0.6726]  time: 0.0802  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4220/6320]  eta: 0:02:35  lr: 0.000067  combined_loss: [local: 0.6835 | reduced: 0.6729]  time: 0.0826  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4240/6320]  eta: 0:02:34  lr: 0.000067  combined_loss: [local: 0.5879 | reduced: 0.6729]  time: 0.0816  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4260/6320]  eta: 0:02:32  lr: 0.000067  combined_loss: [local: 0.6202 | reduced: 0.6728]  time: 0.0791  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4280/6320]  eta: 0:02:31  lr: 0.000068  combined_loss: [local: 0.5920 | reduced: 0.6727]  time: 0.0765  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4300/6320]  eta: 0:02:29  lr: 0.000068  combined_loss: [local: 0.5873 | reduced: 0.6725]  time: 0.0770  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4320/6320]  eta: 0:02:28  lr: 0.000068  combined_loss: [local: 0.5878 | reduced: 0.6725]  time: 0.0768  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4340/6320]  eta: 0:02:26  lr: 0.000069  combined_loss: [local: 0.6912 | reduced: 0.6727]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4360/6320]  eta: 0:02:25  lr: 0.000069  combined_loss: [local: 0.6355 | reduced: 0.6727]  time: 0.0763  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4380/6320]  eta: 0:02:24  lr: 0.000069  combined_loss: [local: 0.6624 | reduced: 0.6726]  time: 0.0771  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4400/6320]  eta: 0:02:22  lr: 0.000070  combined_loss: [local: 0.6539 | reduced: 0.6726]  time: 0.0763  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [4420/6320]  eta: 0:02:21  lr: 0.000070  combined_loss: [local: 0.5831 | reduced: 0.6723]  time: 0.0765  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4440/6320]  eta: 0:02:19  lr: 0.000070  combined_loss: [local: 0.5786 | reduced: 0.6721]  time: 0.0763  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4460/6320]  eta: 0:02:18  lr: 0.000071  combined_loss: [local: 0.6396 | reduced: 0.6723]  time: 0.0771  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4480/6320]  eta: 0:02:16  lr: 0.000071  combined_loss: [local: 0.5275 | reduced: 0.6721]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4500/6320]  eta: 0:02:15  lr: 0.000071  combined_loss: [local: 0.7442 | reduced: 0.6724]  time: 0.0766  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4520/6320]  eta: 0:02:13  lr: 0.000072  combined_loss: [local: 0.6479 | reduced: 0.6724]  time: 0.0759  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4540/6320]  eta: 0:02:12  lr: 0.000072  combined_loss: [local: 0.7230 | reduced: 0.6726]  time: 0.0771  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4560/6320]  eta: 0:02:10  lr: 0.000072  combined_loss: [local: 0.6396 | reduced: 0.6725]  time: 0.0762  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4580/6320]  eta: 0:02:09  lr: 0.000072  combined_loss: [local: 0.7219 | reduced: 0.6727]  time: 0.0769  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4600/6320]  eta: 0:02:07  lr: 0.000073  combined_loss: [local: 0.5706 | reduced: 0.6723]  time: 0.0767  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4620/6320]  eta: 0:02:06  lr: 0.000073  combined_loss: [local: 0.6254 | reduced: 0.6723]  time: 0.0769  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [4640/6320]  eta: 0:02:04  lr: 0.000073  combined_loss: [local: 0.5620 | reduced: 0.6722]  time: 0.0769  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4660/6320]  eta: 0:02:03  lr: 0.000074  combined_loss: [local: 0.5710 | reduced: 0.6720]  time: 0.0769  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4680/6320]  eta: 0:02:01  lr: 0.000074  combined_loss: [local: 0.6840 | reduced: 0.6720]  time: 0.0763  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4700/6320]  eta: 0:02:00  lr: 0.000074  combined_loss: [local: 0.6934 | reduced: 0.6719]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4720/6320]  eta: 0:01:59  lr: 0.000075  combined_loss: [local: 0.6763 | reduced: 0.6719]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4740/6320]  eta: 0:01:57  lr: 0.000075  combined_loss: [local: 0.5830 | reduced: 0.6720]  time: 0.0767  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4760/6320]  eta: 0:01:56  lr: 0.000075  combined_loss: [local: 0.5924 | reduced: 0.6719]  time: 0.0766  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4780/6320]  eta: 0:01:54  lr: 0.000076  combined_loss: [local: 0.6332 | reduced: 0.6719]  time: 0.0800  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4800/6320]  eta: 0:01:53  lr: 0.000076  combined_loss: [local: 0.5961 | reduced: 0.6717]  time: 0.0785  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4820/6320]  eta: 0:01:51  lr: 0.000076  combined_loss: [local: 0.5898 | reduced: 0.6714]  time: 0.0776  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4840/6320]  eta: 0:01:50  lr: 0.000077  combined_loss: [local: 0.5917 | reduced: 0.6714]  time: 0.0762  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4860/6320]  eta: 0:01:48  lr: 0.000077  combined_loss: [local: 0.5661 | reduced: 0.6713]  time: 0.0769  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4880/6320]  eta: 0:01:47  lr: 0.000077  combined_loss: [local: 0.4978 | reduced: 0.6709]  time: 0.0768  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4900/6320]  eta: 0:01:45  lr: 0.000078  combined_loss: [local: 0.5287 | reduced: 0.6708]  time: 0.0763  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4920/6320]  eta: 0:01:44  lr: 0.000078  combined_loss: [local: 0.5174 | reduced: 0.6707]  time: 0.0766  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4940/6320]  eta: 0:01:42  lr: 0.000078  combined_loss: [local: 0.5482 | reduced: 0.6705]  time: 0.0766  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [4960/6320]  eta: 0:01:41  lr: 0.000078  combined_loss: [local: 0.5433 | reduced: 0.6702]  time: 0.0766  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [4980/6320]  eta: 0:01:39  lr: 0.000079  combined_loss: [local: 0.5448 | reduced: 0.6703]  time: 0.0771  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5000/6320]  eta: 0:01:38  lr: 0.000079  combined_loss: [local: 0.5215 | reduced: 0.6701]  time: 0.0767  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5020/6320]  eta: 0:01:36  lr: 0.000079  combined_loss: [local: 0.6052 | reduced: 0.6701]  time: 0.0765  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [5040/6320]  eta: 0:01:35  lr: 0.000080  combined_loss: [local: 0.5294 | reduced: 0.6700]  time: 0.0774  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5060/6320]  eta: 0:01:33  lr: 0.000080  combined_loss: [local: 0.5822 | reduced: 0.6698]  time: 0.0768  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5080/6320]  eta: 0:01:32  lr: 0.000080  combined_loss: [local: 0.6575 | reduced: 0.6702]  time: 0.0759  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5100/6320]  eta: 0:01:31  lr: 0.000081  combined_loss: [local: 0.6480 | reduced: 0.6703]  time: 0.0767  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5120/6320]  eta: 0:01:29  lr: 0.000081  combined_loss: [local: 0.6206 | reduced: 0.6704]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5140/6320]  eta: 0:01:28  lr: 0.000081  combined_loss: [local: 0.6247 | reduced: 0.6703]  time: 0.0770  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [5160/6320]  eta: 0:01:26  lr: 0.000082  combined_loss: [local: 0.6318 | reduced: 0.6703]  time: 0.0763  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5180/6320]  eta: 0:01:25  lr: 0.000082  combined_loss: [local: 0.6442 | reduced: 0.6703]  time: 0.0767  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5200/6320]  eta: 0:01:23  lr: 0.000082  combined_loss: [local: 0.6150 | reduced: 0.6702]  time: 0.0771  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5220/6320]  eta: 0:01:22  lr: 0.000083  combined_loss: [local: 0.6453 | reduced: 0.6703]  time: 0.0768  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5240/6320]  eta: 0:01:20  lr: 0.000083  combined_loss: [local: 0.5851 | reduced: 0.6700]  time: 0.0766  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5260/6320]  eta: 0:01:19  lr: 0.000083  combined_loss: [local: 0.5710 | reduced: 0.6699]  time: 0.0753  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5280/6320]  eta: 0:01:17  lr: 0.000084  combined_loss: [local: 0.5733 | reduced: 0.6699]  time: 0.0756  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5300/6320]  eta: 0:01:16  lr: 0.000084  combined_loss: [local: 0.6590 | reduced: 0.6700]  time: 0.0760  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [5320/6320]  eta: 0:01:14  lr: 0.000084  combined_loss: [local: 0.5689 | reduced: 0.6699]  time: 0.0756  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5340/6320]  eta: 0:01:13  lr: 0.000084  combined_loss: [local: 0.6788 | reduced: 0.6700]  time: 0.0757  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5360/6320]  eta: 0:01:11  lr: 0.000085  combined_loss: [local: 0.6757 | reduced: 0.6700]  time: 0.0758  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5380/6320]  eta: 0:01:10  lr: 0.000085  combined_loss: [local: 0.5998 | reduced: 0.6700]  time: 0.0753  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5400/6320]  eta: 0:01:08  lr: 0.000085  combined_loss: [local: 0.5363 | reduced: 0.6698]  time: 0.0759  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5420/6320]  eta: 0:01:07  lr: 0.000086  combined_loss: [local: 0.5538 | reduced: 0.6696]  time: 0.0753  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5440/6320]  eta: 0:01:05  lr: 0.000086  combined_loss: [local: 0.7822 | reduced: 0.6698]  time: 0.0756  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5460/6320]  eta: 0:01:04  lr: 0.000086  combined_loss: [local: 0.6029 | reduced: 0.6700]  time: 0.0755  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5480/6320]  eta: 0:01:02  lr: 0.000087  combined_loss: [local: 0.5905 | reduced: 0.6699]  time: 0.0761  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5500/6320]  eta: 0:01:01  lr: 0.000087  combined_loss: [local: 0.6180 | reduced: 0.6700]  time: 0.0754  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5520/6320]  eta: 0:00:59  lr: 0.000087  combined_loss: [local: 0.6653 | reduced: 0.6701]  time: 0.0823  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5540/6320]  eta: 0:00:58  lr: 0.000088  combined_loss: [local: 0.6917 | reduced: 0.6702]  time: 0.0815  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5560/6320]  eta: 0:00:56  lr: 0.000088  combined_loss: [local: 0.6399 | reduced: 0.6701]  time: 0.0814  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5580/6320]  eta: 0:00:55  lr: 0.000088  combined_loss: [local: 0.6007 | reduced: 0.6699]  time: 0.0791  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5600/6320]  eta: 0:00:53  lr: 0.000089  combined_loss: [local: 0.5918 | reduced: 0.6699]  time: 0.0825  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [5620/6320]  eta: 0:00:52  lr: 0.000089  combined_loss: [local: 0.5728 | reduced: 0.6699]  time: 0.0806  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5640/6320]  eta: 0:00:50  lr: 0.000089  combined_loss: [local: 0.5578 | reduced: 0.6699]  time: 0.0799  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5660/6320]  eta: 0:00:49  lr: 0.000090  combined_loss: [local: 0.6348 | reduced: 0.6700]  time: 0.0782  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5680/6320]  eta: 0:00:47  lr: 0.000090  combined_loss: [local: 0.6563 | reduced: 0.6701]  time: 0.0785  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [5700/6320]  eta: 0:00:46  lr: 0.000090  combined_loss: [local: 0.5841 | reduced: 0.6700]  time: 0.0783  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5720/6320]  eta: 0:00:44  lr: 0.000091  combined_loss: [local: 0.6976 | reduced: 0.6701]  time: 0.0781  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [5740/6320]  eta: 0:00:43  lr: 0.000091  combined_loss: [local: 0.6100 | reduced: 0.6702]  time: 0.0775  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5760/6320]  eta: 0:00:41  lr: 0.000091  combined_loss: [local: 0.5798 | reduced: 0.6699]  time: 0.0782  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [5780/6320]  eta: 0:00:40  lr: 0.000091  combined_loss: [local: 0.5808 | reduced: 0.6699]  time: 0.0783  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5800/6320]  eta: 0:00:38  lr: 0.000092  combined_loss: [local: 0.5647 | reduced: 0.6699]  time: 0.0789  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5820/6320]  eta: 0:00:37  lr: 0.000092  combined_loss: [local: 0.6235 | reduced: 0.6699]  time: 0.0784  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [5840/6320]  eta: 0:00:35  lr: 0.000092  combined_loss: [local: 0.6453 | reduced: 0.6700]  time: 0.0777  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5860/6320]  eta: 0:00:34  lr: 0.000093  combined_loss: [local: 0.6242 | reduced: 0.6701]  time: 0.0774  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [5880/6320]  eta: 0:00:32  lr: 0.000093  combined_loss: [local: 0.6225 | reduced: 0.6701]  time: 0.0778  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [5900/6320]  eta: 0:00:31  lr: 0.000093  combined_loss: [local: 0.5926 | reduced: 0.6701]  time: 0.0776  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5920/6320]  eta: 0:00:30  lr: 0.000094  combined_loss: [local: 0.5439 | reduced: 0.6699]  time: 0.0773  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5940/6320]  eta: 0:00:28  lr: 0.000094  combined_loss: [local: 0.5434 | reduced: 0.6699]  time: 0.0775  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [5960/6320]  eta: 0:00:27  lr: 0.000094  combined_loss: [local: 0.6555 | reduced: 0.6700]  time: 0.0773  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [5980/6320]  eta: 0:00:25  lr: 0.000095  combined_loss: [local: 0.5995 | reduced: 0.6698]  time: 0.0776  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [6000/6320]  eta: 0:00:24  lr: 0.000095  combined_loss: [local: 0.5838 | reduced: 0.6699]  time: 0.0770  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6020/6320]  eta: 0:00:22  lr: 0.000095  combined_loss: [local: 0.5875 | reduced: 0.6699]  time: 0.0777  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6040/6320]  eta: 0:00:21  lr: 0.000096  combined_loss: [local: 0.7196 | reduced: 0.6700]  time: 0.0766  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6060/6320]  eta: 0:00:19  lr: 0.000096  combined_loss: [local: 0.6925 | reduced: 0.6701]  time: 0.0770  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6080/6320]  eta: 0:00:18  lr: 0.000096  combined_loss: [local: 0.5901 | reduced: 0.6698]  time: 0.0766  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6100/6320]  eta: 0:00:16  lr: 0.000097  combined_loss: [local: 0.6211 | reduced: 0.6697]  time: 0.0769  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6120/6320]  eta: 0:00:15  lr: 0.000097  combined_loss: [local: 0.5830 | reduced: 0.6696]  time: 0.0766  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6140/6320]  eta: 0:00:13  lr: 0.000097  combined_loss: [local: 0.6628 | reduced: 0.6696]  time: 0.0764  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6160/6320]  eta: 0:00:12  lr: 0.000097  combined_loss: [local: 0.5742 | reduced: 0.6696]  time: 0.0762  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6180/6320]  eta: 0:00:10  lr: 0.000098  combined_loss: [local: 0.5709 | reduced: 0.6697]  time: 0.0773  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6200/6320]  eta: 0:00:09  lr: 0.000098  combined_loss: [local: 0.6274 | reduced: 0.6696]  time: 0.0769  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6220/6320]  eta: 0:00:07  lr: 0.000098  combined_loss: [local: 0.6533 | reduced: 0.6697]  time: 0.0777  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6240/6320]  eta: 0:00:06  lr: 0.000099  combined_loss: [local: 0.6784 | reduced: 0.6697]  time: 0.0767  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6260/6320]  eta: 0:00:04  lr: 0.000099  combined_loss: [local: 0.6915 | reduced: 0.6697]  time: 0.0777  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [6280/6320]  eta: 0:00:03  lr: 0.000099  combined_loss: [local: 0.6389 | reduced: 0.6697]  time: 0.0772  data: 0.0002  max mem: 1017\n",
      "Epoch: [0]  [6300/6320]  eta: 0:00:01  lr: 0.000100  combined_loss: [local: 0.5680 | reduced: 0.6695]  time: 0.0773  data: 0.0001  max mem: 1017\n",
      "Epoch: [0]  [6319/6320]  eta: 0:00:00  lr: 0.000100  combined_loss: [local: 0.5527 | reduced: 0.6696]  time: 0.0749  data: 0.0002  max mem: 1017\n",
      "Epoch: [0] Total time: 0:07:55 (0.0752 s / it)\n",
      "Averaged stats: lr: 0.000100  combined_loss: [local: 0.5527 | reduced: 0.6696]\n",
      "Epoch 0 training stats: {'lr': 4.9992088607594954e-05, 'combined_loss': 0.6695692245294399}\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "best_evaluate_metric_value = 0\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    # train for one epoch\n",
    "    train_stats = train_one_epoch(\n",
    "        model, \n",
    "        data_loader_train,\n",
    "        optimizer, \n",
    "        device, \n",
    "        epoch, \n",
    "        loss_scaler,\n",
    "        log_writer=log_writer,\n",
    "        log_per_epoch_count=args.log_per_epoch_count,\n",
    "        args=args\n",
    "    )\n",
    "    print(f\"Epoch {epoch} training stats: {train_stats}\")\n",
    "    break\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forensichub2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
